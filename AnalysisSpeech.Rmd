---
title: "Analysis Speech"
author: "Tom Offrede"
date: "2022-09-15"
output:
  html_document:
    toc: true
    toc_float: 
      collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(tidyverse)
library(lme4)
library(ggdist)

`%!in%` <- Negate(`%in%`)

folder <- "C:/Users/offredet/Documents/1HU/ExperimentEyes/Data/All/"
files <- list.files(folder, "RData")
fileBase <- files[grepl("Baseline", files)]
fileConv <- files[grepl("Conversation", files) & !grepl("Including", files)]

load(paste0(folder, "dataBaseline.RData"))
load(paste0(folder, "dataConversation.RData"))

dac <- dac[!grepl("Impairment|Dyslexia|Gender|Education|Age", names(dac))]

dac <- dac %>%
  filter(!grepl("Robot", speaker)) %>% 
  mutate_at(c("turnDur", "turn", "f0mean", "f0sd", "intensMean", "intensMax", "robPrevf0mean", "robPrevf0meanMock", "gapDur", "intimMean", "intimSD", "intimMed", "IPUDur", "robPrevf0sd", "robPrevf0sdMock", "robPrevIntMean", "robPrevIntMeanMock", "robPrevIntMax", "robPrevIntMaxMock"), as.numeric) %>%
  mutate_at(c("speaker", "condition", "Order", "task"), as.factor) %>% 
  group_by(speaker) %>%
  mutate(turnDurNormal = (turnDur - min(turnDur, na.rm = TRUE)) / (max(turnDur, na.rm = TRUE) - min(turnDur, na.rm = TRUE)),
         turnDurc = turnDur - mean(turnDur, na.rm=TRUE),
         robf0meanc = robPrevf0mean - mean(robPrevf0mean, na.rm=TRUE),
         robf0sdc = robPrevf0sd - mean(robPrevf0sd, na.rm=TRUE),
         robIntMeanc = robPrevIntMean - mean(robPrevIntMean, na.rm=TRUE),
         robIntMaxc = robPrevIntMax - mean(robPrevIntMax, na.rm=TRUE),
         intimc = intimMean - mean(intimMean, na.rm=TRUE),
         intensMeanC = intensMean - mean(intensMean, na.rm=TRUE),
         intensMaxC = intensMax - mean(intensMax, na.rm=TRUE),
         f0CV = f0sd / f0mean,
         robf0CV = robPrevf0sd / robPrevf0mean,
         robf0CVc = robf0CV - mean(robf0CV, na.rm=TRUE),
         mockf0meanC = robPrevf0meanMock - mean(robPrevf0meanMock, na.rm=TRUE),
         mockf0sdC = robPrevf0sdMock - mean(robPrevf0sdMock, na.rm=TRUE),
         mockf0CV = robPrevf0sdMock / robPrevf0meanMock,
         mockf0CVc = mockf0CV - mean(mockf0CV, na.rm=TRUE),
         f0sdZ = (f0sd - mean(f0sd, na.rm=TRUE))/sd(f0sd, na.rm=TRUE),
         robf0sdZ = robf0sdc / sd(robPrevf0sd, na.rm=TRUE),
         f0CVz = (f0CV - mean(f0CV, na.rm=TRUE))/sd(f0CV, na.rm=TRUE),
         robf0CVz = robf0CVc / sd(robf0CV, na.rm=TRUE),
         f0meanZ = (f0mean - mean(f0mean, na.rm=TRUE))/sd(f0mean, na.rm=TRUE),
         robf0meanZ = robf0meanc / sd(robPrevf0mean, na.rm = TRUE)) %>%
  ungroup() %>% 
  mutate(ESc = EmotionalStability - mean(EmotionalStability, na.rm=TRUE),
         Agreec = Agreeableness - mean(Agreeableness, na.rm=TRUE),
         Conscc = Conscientiousness - mean(Conscientiousness, na.rm=TRUE),
         Extrac = Extraversion - mean(Extraversion, na.rm=TRUE),
         IOc = IntellectOpenness - mean(IntellectOpenness, na.rm=TRUE),
         ConvQualc = PCConvQuality - mean(PCConvQuality, na.rm=TRUE),
         EvalRobotc = PCEvalRobot - mean(PCEvalRobot, na.=TRUE),
         IPUDurC = IPUDur - mean(IPUDur, na.rm=TRUE)) #%>% 
  # filter(scoreEN > 60) # see with and without low-level participants


dab <- dab %>%
  mutate_at(c("condition"), as.factor) %>% 
  group_by(speaker) %>% 
  mutate(robf0meanc = robPrevf0mean - mean(robPrevf0mean, na.rm=TRUE),
         robf0sdc = robPrevf0sd - mean(robPrevf0sd, na.rm=TRUE),
         mockf0meanC = robPrevf0meanMock - mean(robPrevf0meanMock, na.rm=TRUE),
         mockf0sdC = robPrevf0sdMock - mean(robPrevf0sdMock, na.rm=TRUE)) %>% 
  ungroup()
```

## Conditions:
**GA: Gaze Aversion; the robot produced gaze aversion. Experimental condition.**
**NG: No Gaze aversion; the robot stared constantly at the human. Control condition.**

# Between-Turn Gap Duration

```{r}
ggplot(dac, aes(condition, gapDur))+
  geom_boxplot()

ggplot(dac, aes(turnNormal, gapDur))+
  geom_point()+
  facet_wrap(~condition)+
  geom_smooth(method="loess")
```

* There is a `turn` effect: longer gaps throughout the interaction. This model was better than the one using `intimacy` values
* There is **no `condition` effect**


```{r}
dac$condition <- relevel(dac$condition, ref="NG")
summary(g1 <- lmer(gapDur ~ condition * turnNormal + (1 + condition | speaker), dac))
summary(g2 <- lmer(gapDur ~ condition * intimc + (1 + condition | speaker), dac))
anova(g1, g2)
```

# Turn Duration

```{r}
ggplot(dac %>% filter(!grepl("Robot", speaker)), aes(condition, turnDur))+
  geom_boxplot()

ggplot(dac %>% filter(!grepl("Robot", speaker)), aes(turnNormal, turnDur))+
  geom_point()+
  facet_wrap(~condition)+
  geom_smooth(method="loess")
```

* There is a `turn` effect: the further into the conversation, the longer the turns
* There is a `turn : condition` interaction: in the GA condition (robot looks away; i.e. objectively more humanlike) the turns get longer throughout the conversation

The order of the `turn` has a .95 correlation with `intimacy` ratings, since the questions always followed the same order. So we can't say if turn duration got higher with the progression of the conversation or because the questions got more intimate, or simply because the questions got more elaborate (so people had more things to talk about).

So if we make a model with `turn` or `intimacy`, both give the same results -- the one with `turn` showing slightly larger effect sizes. The model with `turn` also has considerably lower AIC.

```{r}
cor.test(dac$turnNormal, dac$intimMean)

dac$condition <- relevel(dac$condition, ref="NG")
summary(t1 <- lmer(turnDur ~ condition * turnNormal + (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))

summary(t2 <- lmer(turnDur ~ condition * intimMean + (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))

anova(t1, t2)
```

# f0 during conversation

## Look closer at f0 throughout time

(Check plots saved)

```{r}
# folderRobF0 <- "C:/Users/offredet/Documents/1HU/ExperimentEyes/Data/RobotsF0/"
# dat <- dac %>% filter(grepl("Robot", speaker))
# 
# for(r in unique(dat$speaker)){
#   ggplot(dat %>% filter(speaker==r), aes(as.numeric(timeIndexOverall), f0mean))+
#     geom_point()+
#     facet_wrap(~condition)+
#     geom_smooth(method="loess")
#   ggsave(paste0(folderRobF0, r, ".png"))
# }
# 
# folderPartF0 <- "C:/Users/offredet/Documents/1HU/ExperimentEyes/Data/ParticipantsF0/"
# dat <- dac %>% filter(!grepl("Robot", speaker))
# 
# for(r in unique(dat$speaker)){
#   ggplot(dat %>% filter(speaker==r), aes(as.numeric(timeIndexOverall), f0mean))+
#     geom_point()+
#     facet_wrap(~condition)+
#     geom_smooth(method="loess")
#   ggsave(paste0(folderPartF0, r, ".png"))
# }
```


## Using the f0 from the IPUs of the robot's previous turn as predictors for the f0 of the IPUs of the human's current turn

### f0 mean

```{r}
dat <- dac %>% 
  filter(abs(f0meanZ) < 2.5,
         abs(robf0meanZ) < 2.5)

ggplot(dat, aes(robf0meanc, f0mean))+
  geom_point()+
  facet_wrap(~condition)+
  geom_smooth(method="lm")
```


See:

```{r}
dat <- dac %>% 
  filter(abs(f0meanZ) < 2.5,
         abs(robf0meanZ) < 2.5)

dac$condition <- relevel(dac$condition, ref="NG")

summary(f1 <- lmer(f0mean ~ robf0meanc : condition : turn + (1 + condition | speaker), dat))

```

### f0 SD

```{r}
dat <- dac %>% 
  filter(abs(f0sdZ) < 2.5,
         abs(robf0sdZ) < 2.5)

ggplot(dat %>% filter(condition=="NG"), aes(robf0sdc, f0sd))+
  geom_point()+
  facet_wrap(~as.factor(turn))+
  geom_smooth(method="lm")+
  ggtitle("Fixed Gaze")

ggplot(dat %>% filter(condition=="GA"), aes(robf0sdc, f0sd))+
  geom_point()+
  facet_wrap(~as.factor(turn))+
  geom_smooth(method="lm")+
  ggtitle("Gaze Aversion")
```


* People seem to diverge on F0 SD from the robot that does GA.

```{r}
dat <- dac %>% 
  filter(abs(f0sdZ) < 2.5,
         abs(robf0sdZ) < 2.5)

summary(f2 <- lmer(f0sd ~ robf0sdc : condition : turn : f0mean + (1 + condition | speaker), dat))

par(mfrow=c(2,2))
hist(resid(f2))
qqnorm(resid(f2));qqline(resid(f2))
plot(fitted(f2), resid(f2))
```

#### checking with mock data

* With the mock data there is no effect. So we can probably believe the effect above.

```{r}
summary(f1 <- lmer(f0sd ~ mockf0sdC : condition + (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))

summary(f2 <- lmer(f0sd ~ mockf0sdC : condition : turnNormal + (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))
anova(f1,f2)
```

### f0 coefficient of variation

```{r}
dat <- dac %>% 
  filter(abs(f0CVz) < 2.5,
         abs(robf0CVz) < 2.5)

ggplot(dat, aes(robf0CVc, f0CV))+
  geom_point()+
  facet_wrap(~condition)+
  geom_smooth(method="lm")
```

* Like for f0 SD, the coefficient of variation follows the same pattern.

```{r}
dat <- dac %>% 
  filter(abs(f0CVz) < 2.5,
         abs(robf0CVz) < 2.5)

summary(f1 <- lmer(f0CV ~ robf0CVc : condition + (1 + condition | speaker), dat))
summary(f2 <- lmer(f0CV ~ robf0CVc : condition : turn + (1 + condition | speaker), dat))
anova(f1,f2)

```


#### checking with mock data

* The mock data also shows no effect.

```{r}
summary(f1 <- lmer(f0sd ~ mockf0CVc : condition + (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))
```

### Comparing beginning and end of dialogue

No convergence

```{r, include=FALSE}
dac <- dac %>% mutate(convPhase = ifelse(turn %in% c(1,2), "beginning", ifelse(turn %in% c(5, 6), "end", NA)))

# f0 mean: no convergence
summary(lmer(f0mean ~ robf0meanc : convPhase + (1 | speaker), dac))
summary(lmer(f0mean ~ robf0meanc : condition : convPhase + (1 + condition | speaker), dac))

# f0 SD: no convergence
summary(lmer(f0sd ~ robf0sdc : convPhase + (1 | speaker), dac))
summary(lmer(f0sd ~ robf0sdc : condition : convPhase + (1 + condition | speaker), dac))
```

### Intimacy

#### f0 mean

```{r}
dat <- dac %>% 
  filter(abs(f0meanZ) < 2.5,
         abs(robf0meanZ) < 2.5)

ggplot(dat, aes(intimMean, f0mean))+
  geom_point()+
  facet_wrap(~condition)+
  geom_smooth(method="lm")
```

results from below: intimacy reduces f0 mean and robot (condition nor robot'S f0) doesnt affect this effect. Intensity is not affected by intimacy.

```{r}
dat <- dac

summary(f1a <- lmer(f0mean ~ intimc + (1  | speaker), dat))

summary(f1b <- lmer(f0mean ~ intimc : condition  + (1 | speaker), dat))
anova(f1a, f1b)


summary(f1 <- lmer(intensMean ~ intimc   + (1  | speaker), dat))

summary(f2 <- lmer(f0mean ~ intimc : robf0meanc : condition + intensMeanC + (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))

par(mfrow=c(2,2))
hist(resid(f1))
qqnorm(resid(f1));qqline(resid(f1))
plot(fitted(f1, resid(f1)))
```


#### f0 SD

```{r}
dat <- dac

summary(f1 <- lmer(f0sd ~ intimc : condition + (1 + condition | speaker), dat))



summary(f1 <- lmer(intensMean ~ intimc  + (1  | speaker), dat))

summary(f1 <- lmer(f0sd ~ intimc : robf0sdc : condition + (1 + condition | speaker), dat))


par(mfrow=c(2,2))
hist(resid(f1))
qqnorm(resid(f1));qqline(resid(f1))
plot(fitted(f1, resid(f1)))

##############


summary(lmer(intensMean ~ robIntMeanc : condition : intimc + (1+condition|speaker), dac))
```


#### f0 CV

```{r}
dat <- dac %>% 
  filter(abs(f0CVz) < 2.5,
         abs(robf0CVz) < 2.5)

summary(f1 <- lmer(f0CV ~ intimc + intensMeanC + (1 | speaker), dat))


par(mfrow=c(2,2))
hist(resid(f1))
qqnorm(resid(f1));qqline(resid(f1))
plot(fitted(f1, resid(f1)))
```

### Compare f0 at beginning and end of conversation

```{r}

```


### BFI

For each BFI dimension, I compared a model `f0 ~ robot's f0 : condition : [BFI dimension]` to one without the dimension. Many of the models with the BFI dimension show a t > 2 for the effect of `robot's f0` and `BFI` in the NG condition (but not GA condition). But since I wouldn't expect that all BFI dimensions would predict convergence, I am comparing the AICs of the models with and without BFI. When the AIC of the model *with* BFI is lower (even with the added variable), then we can maybe assume that the BFI effect is meaningful.

**Conclusion** about BFI dimesions:

Maybe emotional stability (I think also called neuroticism) is the only potentially good predictor.

#### Intellect/Openness


```{r}
summary(intel1 <- lmer(f0sd ~ robf0sdc : IOc : condition : turnNormal + (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))

summary(no1 <- lmer(f0sd ~ robf0sdc : condition : turnNormal + (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))
anova(intel1, no1)
```

#### Agreeableness


```{r}
d <- dac %>%
  filter(!grepl("Robot", speaker)) %>% 
  select(f0sd, robf0sdc, Agreec, Agreeableness, condition, speaker, turnNormal) %>% 
  na.omit()

summary(agree1 <- lmer(f0sd ~ robf0sdc : Agreec : condition : turnNormal + (1 +condition| speaker), d))

summary(no1 <- lmer(f0sd ~ robf0sdc : condition : turnNormal + (1+condition | speaker), d))
anova(agree1, no1)


```
#### Conscientiousness


```{r}
d <- dac %>%
  filter(!grepl("Robot", speaker)) %>% 
  select(f0sd, robf0sdc, Conscc, condition, speaker, turnNormal)%>% 
  na.omit()

summary(con1 <- lmer(f0sd ~ robf0sdc : Conscc : condition : turnNormal+ (1 + condition | speaker), d))

summary(no1 <- lmer(f0sd ~ robf0sdc : condition: turnNormal + (1 + condition | speaker), d))
anova(con1, no1)

```

#### EmotionalStability



```{r}
d <- dac %>%
  filter(!grepl("Robot", speaker)) %>% 
  select(f0sd, f0sdZ, robf0sdZ,  robf0sdc, robPrevf0sd, ESc, EmotionalStability, condition, turnNormal, speaker, intimc) %>% 
  na.omit()

d <- d %>% 
  filter(abs(f0sdZ) < 2.5,
         abs(robf0sdZ)<2.5)

summary(em0c <- lmer(f0sd ~ robf0sdc : ESc : turn + intensMeanC + (1 | speaker), dac))

summary(em1c <- lmer(f0sd ~ robf0sdc : ESc  : condition : turn + intensMeanC + (1+condition | speaker), dac))

anova(em0c, em1c)


summary(em2c <- lmer(f0sd ~ robf0sdc : ESc  : turn + intensMeanC + (1  | speaker), dac))

anova(em2c, em1c)

summary(no1 <- lmer(f0sd ~ robf0sdc : condition : turnNormal + (1 + condition | speaker), d))
anova(em1c, no1)


# with mock data
summary(em0c <- lmer(f0sd ~ mockf0sdC : ESc : turn + intensMeanC + (1 | speaker), dac))



```

#### Extraversion


```{r}
summary(ex1 <- lmer(f0sd ~ robf0sdc : Extrac : condition :turn+ (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))

summary(no1 <- lmer(f0sd ~ robf0sdc : condition : turnNormal+ (1 + condition | speaker), dac %>% filter(!grepl("Robot", speaker))))
anova(ex1, no1)
```


### Questionnaire dimensions

Same procedure as for the BFI dimensions. **THESE MODELS CONFLATE BOTH CONDITIONS**

These 2 dimensions were obtained through a PCA of the questionnaire ratings. I am calling them *Conversational Quality* and *Robot's Quality*. These are the items making up each dimension:

**Conversational quality**:

* My conversation with the robot flowed well.
* I was able to understand when the robot wanted me to speak.
* I was able to understand when the robot wanted to keep speaking.
* I enjoyed talking with the robot.
* I felt positively about the robot.
* I felt positively about the conversation.
* I felt comfortable while talking with the robot.

**Robot's quality**:

* The robot responded to me at the appropriate time.
* The robot’s face was very human-like.
* The robot’s voice was very human-like.
* The robot’s behavior was very human-like.

**Conclusion** of questionnaire dimensions: There is a tendency for *conversational quality* and *robot's quality* to predict convergence. See details for each dimension below.

#### Principal Component: Conversation Quality

AIC is slightly lower and t value higher. People that rated the conversation as better quality (see above) seemed to converge to the robot more.

```{r}
summary(cf1 <- lmer(f0sd ~ robf0sdc : ConvQualc : turnNormal + (1 | speaker), dac %>% filter(!grepl("Robot", speaker))))

summary(no1 <- lmer(f0sd ~ robf0sdc : turnNormal + (1 | speaker), dac %>% filter(!grepl("Robot", speaker))))
anova(cf1, no1)
```

#### Principal Component: Robot's Quality

AIC is slightly lower and t value higher. So there seems to be a tendency for people to converge more to the robot they rated as higher quality.

```{r}
summary(hl1 <- lmer(f0sd ~ robf0sdc : EvalRobotc : turnNormal + (1  | speaker), dac %>% filter(!grepl("Robot", speaker))))

summary(no1 <- lmer(f0sd ~ robf0sdc : turnNormal + (1 | speaker), dac %>% filter(!grepl("Robot", speaker))))
anova(hl1, no1)
```


  
## Using the difference between the human's mean f0 in the current turn and the robot's mean f0 in the preceding turn


```{r}
ggplot(dat, aes(condition, f0Diff))+
  geom_boxplot()

ggplot(dat, aes(turnNormal, f0Diff))+
  geom_point()+
  facet_wrap(~condition)+
  geom_smooth(method="lm")
```

Using this method we don't see any effect on f0.

```{r}
summary(ft1 <- lmer(f0Diff ~ condition * turnNormal + (1 + condition | speaker), dat))
```

# f0 during baseline

### f0 mean

```{r}
ggplot(dab, aes(robPrevf0mean, f0mean))+
  geom_point()+
  facet_wrap(~condition)+
  geom_smooth(method="loess")
```

There is no lasting convergence effect in f0 mean.

```{r}
dab$condition <- relevel(dab$condition, ref="GA")
summary(fb1 <- lmer(f0mean ~  robf0meanc + (1 | speaker), dab))
summary(fb2 <- lmer(f0mean ~  robf0meanc  : condition + (1 + condition | speaker), dab))
```

Also no "convergence" with mock data.

```{r}
summary(fbM <- lmer(f0mean ~ mockf0meanC + (1 | speaker), dab))
summary(fbM <- lmer(f0mean ~ mockf0meanC : condition + (1 | speaker), dab))
```


### f0 SD

```{r}
ggplot(dab, aes(robPrevf0sd, f0sd))+
  geom_point()+
  facet_wrap(~condition)+
  geom_smooth(method="loess")
```

There is no lasting convergence effect in f0 SD.

```{r}
dab$condition <- relevel(dab$condition, ref="GA")
summary(fb1 <- lmer(f0mean ~  robf0sdc + (1 | speaker), dab))
summary(fb2 <- lmer(f0mean ~  robf0sdc  : condition + (1  | speaker), dab))
```

Also no "convergence" with mock data.

```{r}
summary(fbM <- lmer(f0mean ~ mockf0sdC + (1 | speaker), dab))
summary(fbM <- lmer(f0mean ~ mockf0sdC : condition + (1 | speaker), dab))
```

# Questionnaire ratings and condition


```{r}
ggplot(dac, aes(condition, PCConvQuality))+
  stat_halfeye(adjust = .5,  width = .5, justification = -.2, .width = c(.5, .95), fill="#9bafbd")+
  geom_boxplot(width=.13, notch = TRUE)

ggplot(dac, aes(condition, PCConvQuality))+
  geom_boxplot()
```

From the graphs, you'd think there's either no difference between conditions or that `GA` has slightly higher ratings. The regression is confusing about it:

* If you include a random slope of `condition` per `speaker`, the model doesn't converge
* If you only include the random intercept for `speaker`, the condition `NG` is shown to have higher ratings.

I doubt the robustness of this result.

(Model's residuals: homoskedastic (good) but far from normally distributed.)

```{r}
summary(cq1 <- lmer(PCConvQuality ~ condition + (1|speaker), dac))

par(mfrow=c(2,2))
plot(fitted(cq1), resid(cq1))
hist(resid(cq1))
qqnorm(resid(cq1));qqline(resid(cq1))
```


```{r}
ggplot(dac, aes(condition, PCEvalRobot))+
  stat_halfeye(adjust = .5,  width = .5, justification = -.2, .width = c(.5, .95), fill="#9bafbd")+
  geom_boxplot(width=.13, notch = TRUE)
```

For the "robot's quality" ratings, the `NG` condition was rated higher -- opposite from our hypothesis.

(Model's residuals: also homoskedastic (good), and distribution isn't very normal but better than the conversational quality model above.)

```{r}
summary(rq1 <- lmer(PCEvalRobot ~ condition + (1|speaker), dac))

par(mfrow=c(2,2))
plot(fitted(rq1), resid(rq1))
hist(resid(rq1))
qqnorm(resid(rq1));qqline(resid(rq1))
```


